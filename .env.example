# =============================================================================
# AULA AI TUTOR - Variables de Entorno
# =============================================================================
# Copiar este archivo a .env y ajustar los valores según tu configuración.
# =============================================================================

# -----------------------------------------------------------------------------
# Modo de ejecución
# -----------------------------------------------------------------------------
AULA_DEBUG=false

# -----------------------------------------------------------------------------
# Configuración de Ollama
# -----------------------------------------------------------------------------
AULA_OLLAMA__BASE_URL=http://localhost:11434
AULA_OLLAMA__TIMEOUT=120

# -----------------------------------------------------------------------------
# Configuración de servidores OpenAI-compatible (vLLM, llama.cpp, etc.)
# -----------------------------------------------------------------------------
AULA_OPENAI_LOCAL__BASE_URL=http://localhost:8000/v1
AULA_OPENAI_LOCAL__API_KEY=not-needed
AULA_OPENAI_LOCAL__TIMEOUT=120

# -----------------------------------------------------------------------------
# Configuración de HuggingFace
# -----------------------------------------------------------------------------
AULA_HUGGINGFACE__CACHE_DIR=~/.cache/huggingface
AULA_HUGGINGFACE__DEVICE_MAP=auto
AULA_HUGGINGFACE__TORCH_DTYPE=bfloat16
AULA_HUGGINGFACE__LOAD_IN_4BIT=true
AULA_HUGGINGFACE__LOAD_IN_8BIT=false

# -----------------------------------------------------------------------------
# Modelos por defecto
# -----------------------------------------------------------------------------
AULA_MODEL_DEFAULTS__SOLVER_MODEL=ollama/qwen2.5:14b
AULA_MODEL_DEFAULTS__TUTOR_MODEL=ollama/llama3.1:8b
AULA_MODEL_DEFAULTS__EMBEDDING_MODEL=ollama/nomic-embed-text
AULA_MODEL_DEFAULTS__SOLVER_TEMPERATURE=0.1
AULA_MODEL_DEFAULTS__TUTOR_TEMPERATURE=0.7

# -----------------------------------------------------------------------------
# Configuración de Guardrails
# -----------------------------------------------------------------------------
AULA_GUARDRAILS__MANIPULATION_DETECTION_ENABLED=true
AULA_GUARDRAILS__MANIPULATION_THRESHOLD=0.8
AULA_GUARDRAILS__SOLUTION_LEAK_DETECTION_ENABLED=true
AULA_GUARDRAILS__SEMANTIC_SIMILARITY_THRESHOLD=0.75
AULA_GUARDRAILS__STEP_REVELATION_THRESHOLD=0.3

# -----------------------------------------------------------------------------
# Configuración del protocolo A2A
# -----------------------------------------------------------------------------
AULA_A2A__SOLVER_HOST=localhost
AULA_A2A__SOLVER_PORT=8001
AULA_A2A__TUTOR_HOST=localhost
AULA_A2A__TUTOR_PORT=8002
AULA_A2A__CONNECTION_TIMEOUT=30
AULA_A2A__REQUEST_TIMEOUT=120

# -----------------------------------------------------------------------------
# Configuración de rendimiento
# -----------------------------------------------------------------------------
AULA_PERFORMANCE__TARGET_TOKENS_PER_SECOND=30
AULA_PERFORMANCE__GENERATION_TIMEOUT=120
AULA_PERFORMANCE__EMBEDDING_BATCH_SIZE=32
AULA_PERFORMANCE__SOLVER_CACHE_ENABLED=true
AULA_PERFORMANCE__SOLVER_CACHE_MAX_SIZE=1000

# -----------------------------------------------------------------------------
# Configuración de logging
# -----------------------------------------------------------------------------
AULA_LOGGING__LEVEL=INFO
AULA_LOGGING__FORMAT=json
AULA_LOGGING__INCLUDE_TIMESTAMPS=true
AULA_LOGGING__LOG_MODEL_INPUTS=false
AULA_LOGGING__LOG_MODEL_OUTPUTS=false
# AULA_LOGGING__LOG_FILE=/var/log/aula-ai-tutor.log
